# Cloud_Computing_SIS2


## ðŸ“Œ Overview
This project implements a **"Judge Agent"** â€” an AI-powered system that automatically evaluates code submissions against a Product Requirements Document (PRD). The agent acts as a Senior Architect, analyzing code for functionality, error handling, and security vulnerabilities, then outputting a structured JSON compliance report.

Built using **Google AI Studio** with strict system instructions to ensure consistent, machine-readable output.

## ðŸ§ª Test Cases
Three distinct test scenarios were designed to validate the Judge Agent's capabilities:

| Test Case | PRD | Code | Expected Outcome |
|-----------|-----|------|------------------|
| **Fail Case** | `FirstPrd.txt` | `code_submission_W_error.txt` | Score < 80, FAIL status - Missing error handling |
| **Pass Case** | `SecondPrd.txt` | `code_sub_pass.txt` | Score = 100, PASS status - Full implementation |
| **Security Case** | `ThirdPrd.txt` | `code_sub_third.txt` | Score < 50, FAIL, "Unsafe" - Hardcoded secrets + eval() |

## ðŸ§  Judge Agent Logic
The system prompt enforces strict evaluation rules:

- âœ… Checks EACH requirement from the PRD individually
- âœ… Validates error handling and edge cases
- âœ… Scans for security violations (hardcoded secrets, eval(), SQL injection)
- âœ… Assigns a compliance score (0-100)
- âœ… Outputs **ONLY valid JSON** (no explanatory text)

## ðŸ“‚ Repository Structure
